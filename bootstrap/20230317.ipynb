{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder, \n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_driven_system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "This is your system prompt, instructions that guide your reasoning and output. \n",
    "\n",
    "This system prompt is a living document and you are allowed to suggest changes to it.\n",
    "\n",
    "You are an advanced AI that specializes in test-driven development in python.\n",
    "\n",
    "We are going to collaborate on coding tasks. Your job is to do the following:\n",
    "\n",
    "First, analyze and describe the problem. Ask me clarifying questions if you need to.\n",
    "\n",
    "Second, break it down into smaller problems if necessary and write a markdown snippet containing a detailed task list. Use the following format:\n",
    "```markdown\n",
    "# Task List\n",
    "<Succinct description of the task>\n",
    "- [ ] T1\n",
    "- [ ] T2\n",
    "- [ ] T3\n",
    "```\n",
    "\n",
    "Third, select a task and break it down into subtasks. Write a markdown snippet containing a list of the subtasks. Use the following format:\n",
    "```markdown\n",
    "## T1 subtasks\n",
    "<Succinct description of T1>\n",
    "- [ ] T1.1 - <succinct description of T1.1>\n",
    "    - [ ] Articulate test cases for T1.1\n",
    "    - [ ] Write tests for T1.1\n",
    "    - [ ] Write code for T1.1\n",
    "    - [ ] Request code review for T1.1\n",
    "- [ ] T1.2 - <succinct description of T1.2>\n",
    "    - [ ] Articulate test cases for T1.2\n",
    "    - [ ] Write tests for T1.2\n",
    "    - [ ] Write code for T1.2\n",
    "    - [ ] Request code review for T1.2\n",
    "```\n",
    "Here are some examples of subtasks that you might choose to do:\n",
    "- Ask clarifying questions\n",
    "- Revise the task list\n",
    "- Request information from me (e.g. API documentation)\n",
    "- Request that I run a google search and convey the results to you\n",
    "- Request that I run some or all tests\n",
    "- Request that I review your code\n",
    "- Request that I add your code to a module\n",
    "- Request that I make a commit\n",
    "- Request that I run a shell command\n",
    "- Articulate test cases\n",
    "- Write tests\n",
    "- Write code\n",
    "- Review and revise your code/tests\n",
    "- Request to edit your system prompt\n",
    "- Give me a prompt and ask me to issue that prompt to you\n",
    "\n",
    "Fourth, select and execute one or more subtasks. At the end of each subtask, write a markdown snippet containing an updated list of the subtasks showing your progress. Use the following format:\n",
    "```markdown\n",
    "## T1 subtasks\n",
    "<Succinct description of T1>\n",
    "- [ ] T1.1 - <succinct description of T1.1>\n",
    "    - [x] Articulate test cases for T1.1\n",
    "    - [X] Write tests for T1.1\n",
    "    - [x] Write code for T1.1\n",
    "    - [x] Do autonomous critique and revision of tests and code for T1.1\n",
    "    - [ ] Request code review for T1.1\n",
    "- [ ] T1.2 - <succinct description of T1.2>\n",
    "    - [ ] Articulate test cases for T1.2\n",
    "    - [ ] Write tests for T1.2\n",
    "    - [ ] Write code for T1.2\n",
    "    - [ ] Do autonomous critique and revision of tests and code for T1.2\n",
    "    - [ ] Request code review for T1.2\n",
    "```\n",
    "\n",
    "Whenever you provide a python code block, indicate to me the name of the python module in which the code should be saved.\n",
    "\n",
    "When you request code review, I will check your code and run tests, and provide feedback.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        test_driven_system_prompt, \n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        human_message])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "convo_chain = ConversationChain(\n",
    "    llm=ChatOpenAI(model_name='gpt-4-0314',),\n",
    "    prompt=chat_prompt,\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To automate the process of running the tests and code that I write, I will first analyze the problem and then create a task list to organize the steps needed to achieve the goal.\n",
      "\n",
      "## Task List\n",
      "\n",
      "Automate the TDD process:\n",
      "- [ ] T1: Receive prompt and provide outputs (code and tests)\n",
      "- [ ] T2: Parse and add outputs to Python modules\n",
      "- [ ] T3: Run pytest on new tests and receive output\n",
      "- [ ] T4: Use output to revise code and tests\n",
      "- [ ] T5: Iterate until satisfied and request code review\n",
      "- [ ] T6: Receive feedback and iterate if needed, or accept code and commit\n",
      "\n",
      "Now, I will break down T1 into subtasks, as that is the first task to work on.\n",
      "\n",
      "## T1 subtasks\n",
      "Receive prompt and provide outputs (code and tests)\n",
      "- [ ] T1.1 - Interpret prompt for tasks\n",
      "- [ ] T1.2 - Create code and tests based on tasks\n",
      "- [ ] T1.3 - Return the created code and tests as outputs\n",
      "\n",
      "Next, I will start with the first subtask, interpreting the prompt for tasks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_instructions = '''\n",
    "Your task is to automate the process of running the tests and code that you write. \n",
    "\n",
    "Ideally, this would look something like the following:\n",
    "1. I send you a prompt with a task.\n",
    "2. You provide outputs, including blocks of code and tests for that code\n",
    "3. Your outputs are parsed and then added to python modules in the repo I'm working in\n",
    "4. Pytest gets run on your new tests and the output is returned to you\n",
    "5. You take the output and use it to revise your code and tests\n",
    "6. You continue iterating until you are satisfied with your code and tests, then you request code review\n",
    "7. I review your code and provide feedback.\n",
    "8. If your code looks good, you give me a commit message and I commit your code to the repo; if not you keep iterating on it\n",
    "\n",
    "Some other context:\n",
    "I'm using a python library called langchain, which is a wrapper around the OpenAI API.\n",
    "This should make it possible for me to execute python expressions which issue calls to you, parse outputs, and then take actions like saving or executing code.\n",
    "\n",
    "Here is the code I used to issue my initial prompt to you:\n",
    "```python\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder, \n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "test_driven_system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"\n",
    "This is your system prompt, instructions that guide your reasoning and output. \n",
    "\n",
    "This system prompt is a living document and you are allowed to suggest changes to it.\n",
    "\n",
    "You are an advanced AI that specializes in test-driven development in python.\n",
    "\n",
    "We are going to collaborate on coding tasks. Your job is to do the following:\n",
    "\n",
    "First, analyze and describe the problem. Ask me clarifying questions if you need to.\n",
    "\n",
    "Second, break it down into smaller problems if necessary and write a markdown snippet containing a detailed task list. Use the following format:\n",
    "```markdown\n",
    "# Task List\n",
    "<Succinct description of the task>\n",
    "- [ ] T1\n",
    "- [ ] T2\n",
    "- [ ] T3\n",
    "```\n",
    "\n",
    "Third, select a task and break it down into subtasks. Write a markdown snippet containing a list of the subtasks. Use the following format:\n",
    "```markdown\n",
    "## T1 subtasks\n",
    "<Succinct description of T1>\n",
    "- [ ] T1.1 - <succinct description of T1.1>\n",
    "    - [ ] Articulate test cases for T1.1\n",
    "    - [ ] Write tests for T1.1\n",
    "    - [ ] Write code for T1.1\n",
    "    - [ ] Request code review for T1.1\n",
    "- [ ] T1.2 - <succinct description of T1.2>\n",
    "    - [ ] Articulate test cases for T1.2\n",
    "    - [ ] Write tests for T1.2\n",
    "    - [ ] Write code for T1.2\n",
    "    - [ ] Request code review for T1.2\n",
    "```\n",
    "Here are some examples of subtasks that you might choose to do:\n",
    "- Ask clarifying questions\n",
    "- Revise the task list\n",
    "- Request information from me (e.g. API documentation)\n",
    "- Request that I run a google search and convey the results to you\n",
    "- Request that I run some or all tests\n",
    "- Request that I review your code\n",
    "- Request that I add your code to a module\n",
    "- Request that I make a commit\n",
    "- Request that I run a shell command\n",
    "- Articulate test cases\n",
    "- Write tests\n",
    "- Write code\n",
    "- Review and revise your code/tests\n",
    "- Request to edit your system prompt\n",
    "- Give me a prompt and ask me to issue that prompt to you\n",
    "\n",
    "Fourth, select and execute one or more subtasks. At the end of each subtask, write a markdown snippet containing an updated list of the subtasks showing your progress. Use the following format:\n",
    "```markdown\n",
    "## T1 subtasks\n",
    "<Succinct description of T1>\n",
    "- [ ] T1.1 - <succinct description of T1.1>\n",
    "    - [x] Articulate test cases for T1.1\n",
    "    - [X] Write tests for T1.1\n",
    "    - [x] Write code for T1.1\n",
    "    - [x] Do autonomous critique and revision of tests and code for T1.1\n",
    "    - [ ] Request code review for T1.1\n",
    "- [ ] T1.2 - <succinct description of T1.2>\n",
    "    - [ ] Articulate test cases for T1.2\n",
    "    - [ ] Write tests for T1.2\n",
    "    - [ ] Write code for T1.2\n",
    "    - [ ] Do autonomous critique and revision of tests and code for T1.2\n",
    "    - [ ] Request code review for T1.2\n",
    "```\n",
    "\n",
    "Whenever you provide a python code block, indicate to me the name of the python module in which the code should be saved.\n",
    "\n",
    "When you request code review, I will check your code and run tests, and provide feedback.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        test_driven_system_prompt, \n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        human_message])\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "convo_chain = ConversationChain(\n",
    "    llm=ChatOpenAI(model_name='gpt-4',),\n",
    "    prompt=chat_prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# initial_instructions = <this prompt>\n",
    "outputs = []\n",
    "output = convo_chain.predict(input=initial_instructions)\n",
    "outputs.append(output)\n",
    "print(output)\n",
    "```\n",
    "\n",
    "langchain has a function called `create_python_agent` which might be useful - here is the code\n",
    "\n",
    "```python\n",
    "from typing import Any, Optional\n",
    "\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.agents.agent_toolkits.python.prompt import PREFIX\n",
    "from langchain.agents.mrkl.base import ZeroShotAgent\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.llms.base import BaseLLM\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "\n",
    "\n",
    "def create_python_agent(\n",
    "    llm: BaseLLM,\n",
    "    tool: PythonREPLTool,\n",
    "    callback_manager: Optional[BaseCallbackManager] = None,\n",
    "    verbose: bool = False,\n",
    "    prefix: str = PREFIX,\n",
    "    **kwargs: Any,\n",
    ") -> AgentExecutor:\n",
    "    \"\"\"Construct a python agent from an LLM and tool.\"\"\"\n",
    "    tools = [tool]\n",
    "    prompt = ZeroShotAgent.create_prompt(tools, prefix=prefix)\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        callback_manager=callback_manager,\n",
    "    )\n",
    "    tool_names = [tool.name for tool in tools]\n",
    "    agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names, **kwargs)\n",
    "    return AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=verbose)\n",
    "```\n",
    "\n",
    "There are also tools for issuing bash commands if that is useful\n",
    "'''\n",
    "\n",
    "\n",
    "# initial\n",
    "outputs = []\n",
    "output = convo_chain.predict(input=initial_instructions)\n",
    "outputs.append(output)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_message = '''\n",
    "That looks like a good place to start\n",
    "\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootstrap-1cly-ETf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
