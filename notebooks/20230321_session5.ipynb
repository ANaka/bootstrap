{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder, \n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from bootstrap.base_prompts import system_prompt\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        system_prompt, \n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        human_message])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "convo_chain = ConversationChain(\n",
    "    llm=ChatOpenAI(model_name='gpt-4-0314',),\n",
    "    prompt=chat_prompt,\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the reminder. I'm ready to help you with any coding tasks related to test-driven development in Python. Please provide a task or a problem that you'd like us to work on together.\n"
     ]
    }
   ],
   "source": [
    "initial_instructions = f'''\n",
    "Hi, I'd like to remind you of your instructions:\n",
    "{system_prompt.format().content}\n",
    "'''\n",
    "# initial\n",
    "outputs = []\n",
    "output = convo_chain.predict(input=initial_instructions)\n",
    "outputs.append(output)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing the code. From my understanding, this code does the following:\n",
      "\n",
      "1. Clone a GitHub repository.\n",
      "\n",
      "2. Find documents in the repository with specific file extensions (`.md`, `.mdx`, `.ipynb`).\n",
      "\n",
      "3. Create `Document` objects for each file in the repository and store the file content and GitHub URL as metadata.\n",
      "\n",
      "4. Split the text content of each `Document` object into smaller chunks using the `CharacterTextSplitter`.\n",
      "\n",
      "5. Create a search index (`FAISS`) from the document chunks using embeddings generated from `OpenAIEmbeddings`.\n",
      "\n",
      "6. Load a language model chain (in this case, a QA chain) from the `langchain` library using the `OpenAI` LLM.\n",
      "\n",
      "To better help you, please specify a specific task, question, or problem you'd like to accomplish or solve using this code.\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "I would like for you to be able to read langchain docs. here is some code that I found online and edited a bit:\n",
    "\n",
    "```python\n",
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "def get_github_docs(repo_owner, repo_name):\n",
    "    with tempfile.TemporaryDirectory() as d:\n",
    "        subprocess.check_call(\n",
    "            f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
    "            cwd=d,\n",
    "            shell=True,\n",
    "        )\n",
    "        git_sha = (\n",
    "            subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
    "            .decode(\"utf-8\")\n",
    "            .strip()\n",
    "        )\n",
    "        repo_path = pathlib.Path(d)\n",
    "        doc_files = []\n",
    "        for extension in ['.md', '.mdx', '.ipynb']:\n",
    "            \n",
    "            doc_files.extend(list(repo_path.glob(f\"**/*{extension}\")))\n",
    "\n",
    "        for doc_file in doc_files:\n",
    "            with open(doc_file, \"r\") as f:\n",
    "                relative_path = doc_file.relative_to(repo_path)\n",
    "                github_url = f\"https://github.com/{repo_owner}/{repo_name}/blob/{git_sha}/{relative_path}\"\n",
    "                yield Document(page_content=f.read(), metadata={\"source\": github_url})\n",
    "                \n",
    "sources = get_github_docs(\"hwchase17\", \"langchain\")\n",
    "# list(sources)\n",
    "\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)\n",
    "for source in sources:\n",
    "    for chunk in splitter.split_text(source.page_content):\n",
    "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
    "        \n",
    "search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings())\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0, model_name='gpt-4'))\n",
    "```\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To add the ability to read Langchain docs to my capabilities, we can take the following steps:\n",
      "\n",
      "1. **Retrieve and store documents**: We will need to integrate or adapt the provided code to retrieve and store documents from the Langchain repository. We can store the document contents and relevant metadata such as URLs in the AI's internal memory.\n",
      "\n",
      "2. **Process and split documents**: We will use the `CharacterTextSplitter` to split the documents into smaller chunks. This will help in handling large documents and extracting relevant information for a given query.\n",
      "\n",
      "3. **Generate embeddings**: We will generate embeddings for the document chunks using `OpenAIEmbeddings` or any other preferred language model.\n",
      "\n",
      "4. **Create a search index**: We will create a search index such as the `FAISS` index to store and search the document embedding efficiently.\n",
      "\n",
      "5. **Develop query function**: Create a function that takes a user query, generates its embedding using the same language model, and searches the index for the most relevant documents.\n",
      "\n",
      "6. **Extract relevant information**: For the top relevant documents found, we will use a language model chain like QA, in the provided code `load_qa_with_sources_chain(OpenAI(temperature=0, model_name='gpt-4'))\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "I want to add the ability to read langchain docs to your capabilities. Propose a plan for how you would do this.\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now that we have gone through the plan to add the ability to read Langchain docs, the next steps would be to implement each part of the plan. I will outline the tasks that need to be done for each step.\n",
      "\n",
      "TASKS\n",
      "- [ ] T1: Integrate or adapt the provided code to retrieve and store documents.\n",
      "- [ ] T2: Process and split documents using `CharacterTextSplitter`.\n",
      "- [ ] T3: Generate embeddings for the document chunks.\n",
      "- [ ] T4: Create a search index with `FAISS` or another indexing method.\n",
      "- [ ] T5: Develop a function to process user queries and search the index.\n",
      "- [ ] T6: Extract relevant information from the top documents using a language model chain.\n",
      "\n",
      "Once you are ready to work on a specific task, let me know, and I can help you further with that task.\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As you're looking to continue with the implementation, let's consider T1 first, since it is the first task in the plan:\n",
      "\n",
      "T1: Integrate or adapt the provided code to retrieve and store documents.\n",
      "\n",
      "For this task, we can build a function that takes a repository owner and repository name as input, and returns a list of documents found. The provided code can be adapted and integrated into this function.\n",
      "\n",
      "Would you like me to create a function to retrieve and store documents based on the provided code, or do you have any specific questions or additional requirements you'd like me to address for this task?\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To execute T1, we will create the following function `get_langchain_docs` which takes two required arguments `repo_owner` and `repo_name`. This function is based on the provided code and returns a list of `Document` objects containing the text content and associated metadata.\n",
      "\n",
      "```python\n",
      "def get_langchain_docs(repo_owner: str, repo_name: str) -> list[Document]:\n",
      "    def get_github_docs(repo_owner, repo_name):\n",
      "        with tempfile.TemporaryDirectory() as d:\n",
      "            subprocess.check_call(\n",
      "                f\"git clone --depth 1 https://github.com/{repo_owner}/{repo_name}.git .\",\n",
      "                cwd=d,\n",
      "                shell=True,\n",
      "            )\n",
      "            git_sha = (\n",
      "                subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
      "                .decode(\"utf-8\")\n",
      "                .strip()\n",
      "            )\n",
      "            repo_path = pathlib.Path(d)\n",
      "            doc_files = []\n",
      "            for extension in ['.md', '.mdx', '.ipynb']:\n",
      "                \n",
      "                doc_files.extend(list(repo_path.glob(f\"**/*{extension}\")))\n",
      "\n",
      "            for doc_file in doc_files:\n",
      "                with open(doc_file, \"r\") as f:\n",
      "                    relative_path = doc_file.relative_to(repo_path)\n",
      "                    github_url\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "Go ahead and use your actions to execute T1\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    github_url = f\"https://github.com/{repo_owner}/{repo_name}/blob/{git_sha}/{relative_path}\"\n",
      "                    yield Document(page_content=f.read(), metadata={\"source\": github_url})\n",
      "                    \n",
      "    sources = get_github_docs(repo_owner, repo_name)\n",
      "    return [source for source in sources]\n",
      "\n",
      "```\n",
      "\n",
      "With this `get_langchain_docs` function, you can now retrieve and store Langchain documents, given the repository owner and repository name. This function returns a list of `Document` objects containing the document text and associated metadata, such as the source URL. If you have any questions about this function or would like help executing the tasks T2-T6, please let me know.\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "Continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootstrap-1cly-ETf-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
