{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bootstrap.interface_setup import (\n",
    "    load_environment_variables,\n",
    "    create_human_message_template,\n",
    "    create_chat_prompt,\n",
    "    create_conversation_chain,\n",
    "    system_prompt\n",
    ")\n",
    "\n",
    "load_environment_variables()\n",
    "human_message = create_human_message_template()\n",
    "chat_prompt = create_chat_prompt(human_message)\n",
    "convo_chain = create_conversation_chain(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for the reminder. How can I help you today? Do you have a coding task or project in mind that we can collaborate on?\n"
     ]
    }
   ],
   "source": [
    "initial_instructions = f'''\n",
    "Hi, I'd like to remind you of your instructions:\n",
    "{system_prompt.format().content}\n",
    "'''\n",
    "# initial\n",
    "outputs = []\n",
    "output = convo_chain.predict(input=initial_instructions)\n",
    "outputs.append(output)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*REQUEST TO RUN A SHELL COMMAND*\n",
      "Command: \"tree .\"\n",
      "Reason: To view the structure of the current repo\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "use your actions to figure out how the repo is currently structured.\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing the repo structure. Here's the current structure of the repository:\n",
      "\n",
      "```\n",
      ".\n",
      "├── README.md\n",
      "├── bootstrap\n",
      "│   ├── __init__.py\n",
      "│   ├── __pycache__\n",
      "│   │   ├── __init__.cpython-310.pyc\n",
      "│   │   ├── base_prompts.cpython-310.pyc\n",
      "│   │   └── interface_setup.cpython-310.pyc\n",
      "│   ├── base_prompts.py\n",
      "│   └── interface_setup.py\n",
      "├── notebooks\n",
      "│   ├── 20230317_session1.ipynb\n",
      "│   ├── 20230320_session2.ipynb\n",
      "│   ├── 20230321_session3.ipynb\n",
      "│   └── 20230321_session4.ipynb\n",
      "├── poetry.lock\n",
      "├── pyproject.toml\n",
      "├── qasnippet.ipynb\n",
      "└── tests\n",
      "    └── __init__.py\n",
      "```\n",
      "\n",
      "What would you like to work on within this repo? Please provide more information or a specific task, and we can create a TASK LIST and proceed accordingly.\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "this is what it returns \n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── bootstrap\n",
    "│   ├── __init__.py\n",
    "│   ├── __pycache__\n",
    "│   │   ├── __init__.cpython-310.pyc\n",
    "│   │   ├── base_prompts.cpython-310.pyc\n",
    "│   │   └── interface_setup.cpython-310.pyc\n",
    "│   ├── base_prompts.py\n",
    "│   └── interface_setup.py\n",
    "├── notebooks\n",
    "│   ├── 20230317_session1.ipynb\n",
    "│   ├── 20230320_session2.ipynb\n",
    "│   ├── 20230321_session3.ipynb\n",
    "│   └── 20230321_session4.ipynb\n",
    "├── poetry.lock\n",
    "├── pyproject.toml\n",
    "├── qasnippet.ipynb\n",
    "└── tests\n",
    "    └── __init__.py\n",
    "```\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you write tests for the `interface_setup.py` module. First, I will need to see the contents of the `interface_setup.py` file. \n",
      "\n",
      "*REQUEST INFORMATION*\n",
      "Please provide the content of the \"interface_setup.py\" module.\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "lets write some tests for the interface_setup.py module\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing the contents of the `interface_setup.py` module. Based on the code, I'll create a task list to write tests for this module.\n",
      "\n",
      "*CREATE TASK LIST*\n",
      "```markdown\n",
      "TASKS\n",
      "- [ ] T1: Write tests for the `load_environment_variables` function.\n",
      "- [ ] T2: Write tests for the `create_human_message_template` function.\n",
      "- [ ] T3: Write tests for the `create_chat_prompt` function.\n",
      "- [ ] T4: Write tests for the `create_conversation_chain` function.\n",
      "```\n",
      "\n",
      "Let's start with T1 - writing tests for the `load_environment_variables` function. Since it is a simple wrapper around `load_dotenv`, we'll need to design test cases that ensure environment variables are correctly loaded.\n",
      "\n",
      "What environment variables do you expect to be present after calling `load_environment_variables`? Please provide variable names and their expected values (if possible).\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder, \n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from bootstrap.base_prompts import system_prompt\n",
    "\n",
    "\n",
    "def load_environment_variables():\n",
    "    load_dotenv()\n",
    "\n",
    "\n",
    "def create_human_message_template():\n",
    "    return HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "\n",
    "def create_chat_prompt(human_message):\n",
    "    return ChatPromptTemplate.from_messages(\n",
    "        [system_prompt, MessagesPlaceholder(variable_name=\"history\"), human_message]\n",
    "    )\n",
    "\n",
    "\n",
    "def create_conversation_chain(chat_prompt):\n",
    "    return ConversationChain(\n",
    "        llm=ChatOpenAI(model_name='gpt-4-0314'),\n",
    "        prompt=chat_prompt,\n",
    "        memory=ConversationBufferMemory(return_messages=True),\n",
    "    )\n",
    "\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understood. In this case, we can design the test case to focus on the presence of the `OPENAI_API_KEY` environment variable after calling `load_environment_variables` function. Since the expected value is a secret, we won't be testing for its specific value.\n",
      "\n",
      "Here is the plan on how we can test the `load_environment_variables` function:\n",
      "\n",
      "1. Call the `load_environment_variables` function.\n",
      "2. Verify that the `OPENAI_API_KEY` is present in the environment variables.\n",
      "3. Check that the value of `OPENAI_API_KEY` is not an empty string.\n",
      "\n",
      "Now, let's write the test:\n",
      "\n",
      "*WRITE TESTS*\n",
      "```python\n",
      "import os\n",
      "from bootstrap.interface_setup import load_environment_variables\n",
      "\n",
      "\n",
      "def test_load_environment_variables():\n",
      "    # Ensure the 'OPENAI_API_KEY' variable is not present before execution\n",
      "    if 'OPENAI_API_KEY' in os.environ:\n",
      "        del os.environ['OPENAI_API_KEY']\n",
      "\n",
      "    # Call the load_environment_variables() function\n",
      "    load_environment_variables()\n",
      "\n",
      "    # Assert that the 'OPENAI_API_KEY' is present in the environment variables\n",
      "    assert 'OPENAI_API_KEY' in os.environ\n",
      "\n",
      "    # Assert that the value of 'OPENAI_API_KEY' is not an empty\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "OPENAI_API_KEY is the only environment variable we expect for now. I cannot provide its expected value - it is a secret.\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string\n",
      "\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the abrupt interruption in my previous response. Here's the complete test function for `load_environment_variables`:\n",
      "\n",
      "*WRITE TESTS*\n",
      "```python\n",
      "import os\n",
      "from bootstrap.interface_setup import load_environment_variables\n",
      "\n",
      "\n",
      "def test_load_environment_variables():\n",
      "    # Ensure the 'OPENAI_API_KEY' variable is not present before execution\n",
      "    if 'OPENAI_API_KEY' in os.environ:\n",
      "        del os.environ['OPENAI_API_KEY']\n",
      "\n",
      "    # Call the load_environment_variables() function\n",
      "    load_environment_variables()\n",
      "\n",
      "    # Assert that the 'OPENAI_API_KEY' is present in the environment variables\n",
      "    assert 'OPENAI_API_KEY' in os.environ\n",
      "\n",
      "    # Assert that the value of 'OPENAI_API_KEY' is not an empty string\n",
      "    assert os.environ['OPENAI_API_KEY'] != \"\"\n",
      "```\n",
      "\n",
      "Now that we have the test for the `load_environment_variables` function, let's move on to the next task: writing tests for the `create_human_message_template` function.\n",
      "\n",
      "*UPDATE TASK LIST*\n",
      "```markdown\n",
      "TASKS\n",
      "- [x] T1: Write tests for the `load_environment_variables` function.\n",
      "- [ ] T2: Write tests for the `create_human_message_template` function.\n",
      "- [ ] T3\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Write tests for the `create_chat_prompt` function.\n",
      "- [ ] T4: Write tests for the `create_conversation_chain` function.\n",
      "```\n",
      "\n",
      "For the `create_human_message_template` function, we'll design test cases to ensure that it returns a `HumanMessagePromptTemplate` instance and that the instance's `from_template` method has been called.\n",
      "\n",
      "*ARTICULATE TEST CASES*\n",
      "\n",
      "- Call `create_human_message_template` and verify that it returns a `HumanMessagePromptTemplate` instance.\n",
      "- Check that the instance's `from_template` method has been called with the expected input: \"{input}\"\n",
      "\n",
      "Now, let's write the tests:\n",
      "\n",
      "*WRITE TESTS*\n",
      "```python\n",
      "from unittest.mock import MagicMock, patch\n",
      "from bootstrap.interface_setup import create_human_message_template\n",
      "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
      "\n",
      "\n",
      "def test_create_human_message_template():\n",
      "    # Mock the HumanMessagePromptTemplate.from_template method\n",
      "    with patch.object(HumanMessagePromptTemplate, \"from_template\") as mock_from_template:\n",
      "        # Define the MagicMock instance to be returned when from_template is called\n",
      "        mock_from_template.return_value = MagicMock(spec=HumanMessagePromptTemplate)\n",
      "\n",
      "        # Call create_human_message_template\n",
      "        result = create_human_message_template\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "\n",
      "        # Assert that a HumanMessagePromptTemplate instance is returned\n",
      "        assert isinstance(result, HumanMessagePromptTemplate)\n",
      "\n",
      "        # Assert that the from_template method is called with the expected argument\n",
      "        mock_from_template.assert_called_once_with(\"{input}\")\n",
      "```\n",
      "\n",
      "Now that we have the test for the `create_human_message_template` function, let's move on to the next task: writing tests for the `create_chat_prompt` function.\n",
      "\n",
      "*UPDATE TASK LIST*\n",
      "```markdown\n",
      "TASKS\n",
      "- [x] T1: Write tests for the `load_environment_variables` function.\n",
      "- [x] T2: Write tests for the `create_human_message_template` function.\n",
      "- [ ] T3: Write tests for the `create_chat_prompt` function.\n",
      "- [ ] T4: Write tests for the `create_conversation_chain` function.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's update the test cases for the `load_environment_variables` and `create_human_message_template` functions to use pytest.\n",
      "\n",
      "*REVISE TESTS*\n",
      "```python\n",
      "import os\n",
      "import pytest\n",
      "from unittest.mock import MagicMock, patch\n",
      "from bootstrap.interface_setup import load_environment_variables, create_human_message_template\n",
      "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
      "\n",
      "\n",
      "def test_load_environment_variables():\n",
      "    # Ensure the 'OPENAI_API_KEY' variable is not present before execution\n",
      "    if 'OPENAI_API_KEY' in os.environ:\n",
      "        del os.environ['OPENAI_API_KEY']\n",
      "\n",
      "    # Call the load_environment_variables() function\n",
      "    load_environment_variables()\n",
      "\n",
      "    # Assert that the 'OPENAI_API_KEY' is present in the environment variables\n",
      "    assert 'OPENAI_API_KEY' in os.environ\n",
      "\n",
      "    # Assert that the value of 'OPENAI_API_KEY' is not an empty string\n",
      "    assert os.environ['OPENAI_API_KEY'] != \"\"\n",
      "\n",
      "\n",
      "def test_create_human_message_template():\n",
      "    # Mock the HumanMessagePromptTemplate.from_template method\n",
      "    with patch.object(HumanMessagePromptTemplate, \"from_template\") as mock_from_template:\n",
      "        # Define the MagicMock instance to be returned when from_template is called\n",
      "        mock_from_template\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "lets do everything in pytest please\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To accomplish T3 and T4, updating the task list, and following the test-driven development process, I'll start by writing test cases for the `create_chat_prompt` and `create_conversation_chain` functions and then provide the test code using pytest.\n",
      "\n",
      "*UPDATE TASK LIST*\n",
      "```markdown\n",
      "TASKS\n",
      "- [x] T1: Write tests for the `load_environment_variables` function.\n",
      "- [x] T2: Write tests for the `create_human_message_template` function.\n",
      "- [ ] T3: Write tests for the `create_chat_prompt` function.\n",
      "- [ ] T4: Write tests for the `create_conversation_chain` function.\n",
      "```\n",
      "\n",
      "Let's start with the `create_chat_prompt` function.\n",
      "\n",
      "*ARTICULATE TEST CASES*\n",
      "\n",
      "1. Call the `create_chat_prompt` function with a given `human_message`.\n",
      "2. Assert that the `human_message` exists in the generated `ChatPromptTemplate` instance.\n",
      "3. Check that `system_prompt` and `MessagesPlaceholder` objects are present in the `ChatPromptTemplate` instance.\n",
      "\n",
      "Now, let's write the test for the `create_chat_prompt` function:\n",
      "\n",
      "*WRITE TESTS*\n",
      "```python\n",
      "from bootstrap.interface_setup import create_chat_prompt\n",
      "from langchain\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "okay go ahead and do all of your tasks now\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
      "from bootstrap.base_prompts import system_prompt\n",
      "\n",
      "\n",
      "def test_create_chat_prompt():\n",
      "    # Define a mock human_message\n",
      "    mock_human_message = MagicMock(spec=HumanMessagePromptTemplate)\n",
      "\n",
      "    # Call create_chat_prompt with the mock_human_message\n",
      "    chat_prompt = create_chat_prompt(mock_human_message)\n",
      "\n",
      "    # Assert that the returned object is an instance of ChatPromptTemplate\n",
      "    assert isinstance(chat_prompt, ChatPromptTemplate)\n",
      "\n",
      "    # Assert that the human_message is in the chat_prompt messages\n",
      "    assert mock_human_message in chat_prompt.messages\n",
      "\n",
      "    # Assert that the system_prompt and MessagesPlaceholder are in the chat_prompt messages\n",
      "    assert any(isinstance(msg, type(system_prompt)) for msg in chat_prompt.messages)\n",
      "    assert any(isinstance(msg, MessagesPlaceholder) for msg in chat_prompt.messages)\n",
      "```\n",
      "\n",
      "Now, let's create the test cases and test code for the `create_conversation_chain` function.\n",
      "\n",
      "*ARTICULATE TEST CASES*\n",
      "\n",
      "1. Call the `create_conversation_chain` function with a given `chat_prompt`.\n",
      "2. Assert that the returned object is an instance of `ConversationChain`.\n",
      "3. Assert that the `chat_prompt` object is the same as the provided input.\n",
      "\n",
      "*WRITE TESTS\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from bootstrap.interface_setup import create_conversation_chain\n",
      "from langchain import ConversationChain\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.prompts.chat import ChatPromptTemplate\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "\n",
      "def test_create_conversation_chain():\n",
      "    # Define a mock chat_prompt\n",
      "    mock_chat_prompt = MagicMock(spec=ChatPromptTemplate)\n",
      "\n",
      "    # Call create_conversation_chain with the mock_chat_prompt\n",
      "    conversation_chain = create_conversation_chain(mock_chat_prompt)\n",
      "\n",
      "    # Assert that the returned object is an instance of ConversationChain\n",
      "    assert isinstance(conversation_chain, ConversationChain)\n",
      "\n",
      "    # Assert that the chat_prompt object is the same in conversation_chain\n",
      "    assert conversation_chain.prompt == mock_chat_prompt\n",
      "\n",
      "    # Assert that the language model is an instance of ChatOpenAI\n",
      "    assert isinstance(conversation_chain.llm, ChatOpenAI)\n",
      "\n",
      "    # Assert that the memory is an instance of ConversationBufferMemory\n",
      "    assert isinstance(conversation_chain.memory, ConversationBufferMemory)\n",
      "```\n",
      "\n",
      "Now we have tests for all the functions in the `interface_setup.py` module. Please add the tests to the test suite and run them using pytest.\n",
      "\n",
      "*UPDATE TASK LIST*\n",
      "```markdown\n",
      "TASKS\n",
      "- [x] T1\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears that there were two test failures:\n",
      "\n",
      "1. `test_create_chat_prompt`: The `mock_human_message` object is not directly in the `chat_prompt.messages`. Instead, a copy of the object is present in the list.\n",
      "2. `test_create_conversation_chain`: There is a validation error regarding the prompt input variables. The test setup may not be consistent with the expected input variables in the `ConversationChain` instance.\n",
      "\n",
      "Let's update the test cases and test code to address these issues.\n",
      "\n",
      "*UPDATE TEST CASES AND REVISE TESTS*\n",
      "1. `test_create_chat_prompt`: Instead of asserting that the `mock_human_message` object is in the `chat_prompt.messages`, we can check whether the message has the expected `{input}` format.\n",
      "\n",
      "For `test_create_conversation_chain`, we need more information to identify the root cause of the issue. Can you provide information about the input variables that `ConversationChain` expects, if there is any specific structure or validation rules for it?\n",
      "\n",
      "With the revised test case for `test_create_chat_prompt`, here is the updated test code:\n",
      "\n",
      "*REVISE TESTS*\n",
      "```python\n",
      "def test_create_chat_prompt():\n",
      "    # Define a mock human_message\n",
      "    mock_human_message = MagicMock(spec=HumanMessagePromptTemplate\n"
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "================================================================== FAILURES ===================================================================\n",
    "___________________________________________________________ test_create_chat_prompt ___________________________________________________________\n",
    "\n",
    "    def test_create_chat_prompt():\n",
    "        # Define a mock human_message\n",
    "        mock_human_message = MagicMock(spec=HumanMessagePromptTemplate)\n",
    "    \n",
    "        # Call create_chat_prompt with the mock_human_message\n",
    "        chat_prompt = create_chat_prompt(mock_human_message)\n",
    "    \n",
    "        # Assert that the returned object is an instance of ChatPromptTemplate\n",
    "        assert isinstance(chat_prompt, ChatPromptTemplate)\n",
    "    \n",
    "        # Assert that the human_message is in the chat_prompt messages\n",
    ">       assert mock_human_message in chat_prompt.messages\n",
    "E       AssertionError: assert <MagicMock spec='HumanMessagePromptTemplate' id='4747412864'> in [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, templ...args={}), MessagesPlaceholder(variable_name='history'), <MagicMock name='mock._copy_and_set_values()' id='4747649680'>]\n",
    "E        +  where [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, templ...args={}), MessagesPlaceholder(variable_name='history'), <MagicMock name='mock._copy_and_set_values()' id='4747649680'>] = ChatPromptTemplate(input_variables=['history'], output_parser=None, partial_variables={}, messages=[SystemMessagePromp...rgs={}), MessagesPlaceholder(variable_name='history'), <MagicMock name='mock._copy_and_set_values()' id='4747649680'>]).messages\n",
    "\n",
    "tests/test_interface_setup.py:40: AssertionError\n",
    "_______________________________________________________ test_create_conversation_chain ________________________________________________________\n",
    "\n",
    "    def test_create_conversation_chain():\n",
    "        # Define a mock chat_prompt\n",
    "        mock_chat_prompt = MagicMock(spec=ChatPromptTemplate)\n",
    "    \n",
    "        # Call create_conversation_chain with the mock_chat_prompt\n",
    ">       conversation_chain = create_conversation_chain(mock_chat_prompt)\n",
    "\n",
    "tests/test_interface_setup.py:51: \n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
    "bootstrap/interface_setup.py:29: in create_conversation_chain\n",
    "    return ConversationChain(\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
    "\n",
    ">   ???\n",
    "E   pydantic.error_wrappers.ValidationError: 1 validation error for ConversationChain\n",
    "E   __root__\n",
    "E     Got unexpected prompt input variables. The prompt expects <MagicMock name='mock._copy_and_set_values().input_variables' id='4747764128'>, but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)\n",
    "\n",
    "pydantic/main.py:341: ValidationError\n",
    "=========================================================== short test summary info ===========================================================\n",
    "FAILED tests/test_interface_setup.py::test_create_chat_prompt - AssertionError: assert <MagicMock spec='HumanMessagePromptTemplate' id='4747412864'> in [SystemMessagePromptTemplate(prompt=PromptTemplate...\n",
    "FAILED tests/test_interface_setup.py::test_create_conversation_chain - pydantic.error_wrappers.ValidationError: 1 validation error for ConversationChain\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 8192 tokens. However, you requested 8402 tokens (8146 in the messages, 256 in the completion). Please reduce the length of the messages or completion.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m human_message \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mcontinue\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m'''\u001b[39m\n\u001b[0;32m----> 4\u001b[0m output \u001b[39m=\u001b[39m convo_chain\u001b[39m.\u001b[39;49mpredict(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mhuman_message)\n\u001b[1;32m      5\u001b[0m outputs\u001b[39m.\u001b[39mappend(output)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:151\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:57\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:118\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chains/llm.py:62\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list)\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(prompts, stop)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/base.py:72\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/base.py:69\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     66\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompt_strings, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     70\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/base.py:50\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/base.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m, messages: List[List[BaseMessage]], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Top Level call\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     results \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py:246\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    242\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    243\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 246\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m _create_chat_result(response)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py:222\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/langchain/chat_models/openai.py:220\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/bootstrap-TdbWQQRJ-py3.10/lib/python3.10/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 8192 tokens. However, you requested 8402 tokens (8146 in the messages, 256 in the completion). Please reduce the length of the messages or completion."
     ]
    }
   ],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = '''\n",
    "continue\n",
    "'''\n",
    "output = convo_chain.predict(input=human_message)\n",
    "outputs.append(output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootstrap-TdbWQQRJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
